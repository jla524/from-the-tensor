{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import nnx\n",
    "from tqdm import trange\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "rngs = nnx.Rngs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mnist\")\n",
    "\n",
    "X_train = np.array([np.array(image) for image in dataset[\"train\"][\"image\"]], dtype=np.float32)\n",
    "X_train = np.expand_dims(X_train, -1) / 255.0\n",
    "Y_train = np.array(dataset[\"train\"][\"label\"], dtype=np.int32)\n",
    "\n",
    "X_test = np.array([np.array(image) for image in dataset[\"test\"][\"image\"]], dtype=np.float32)\n",
    "X_test = np.expand_dims(X_test, -1) / 255.0\n",
    "Y_test = np.array(dataset[\"test\"][\"label\"], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nnx.Module):\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), rngs=rngs)\n",
    "        self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "        self.linear1 = nnx.Linear(3136, 256, rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(256, 10, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.avg_pool(nnx.relu(self.conv1(x)))\n",
    "        x = self.avg_pool(nnx.relu(self.conv2(x)))\n",
    "        x = x.reshape(x.shape[0], -1)  # flatten\n",
    "        x = nnx.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06820839 -0.14743432  0.00265857 -0.2173656   0.16673787 -0.00923921\n",
      "  -0.06636689  0.28341877  0.33754364 -0.20142877]]\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(rngs=rngs)\n",
    "y = model(jnp.ones((1, 28, 28, 1)))\n",
    "nnx.display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(model, optax.adamw(learning_rate, momentum))\n",
    "metrics = nnx.MultiMetric(accuracy=nnx.metrics.Accuracy(), loss=nnx.metrics.Average(\"loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: ConvNet, images, labels):\n",
    "    logits = model(images)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=labels).mean()\n",
    "    return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: ConvNet, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, images, labels):\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(model, images, labels)\n",
    "    metrics.update(loss=loss, logits=logits, labels=labels)\n",
    "    optimizer.update(grads)\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: ConvNet, metrics: nnx.MultiMetric, images, labels):\n",
    "    loss, logits = loss_fn(model, images, labels)\n",
    "    metrics.update(loss=loss, logits=logits, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] step: 200, loss: 0.3459, accuracy: 89.43\n",
      "[test] step: 200, loss: 0.1246, accuracy: 95.92\n",
      "[train] step: 400, loss: 0.1196, accuracy: 96.38\n",
      "[test] step: 400, loss: 0.1015, accuracy: 96.58\n",
      "[train] step: 600, loss: 0.0824, accuracy: 97.22\n",
      "[test] step: 600, loss: 0.0968, accuracy: 96.68\n",
      "[train] step: 800, loss: 0.0797, accuracy: 97.69\n",
      "[test] step: 800, loss: 0.0577, accuracy: 98.08\n",
      "[train] step: 1000, loss: 0.0673, accuracy: 98.23\n",
      "[test] step: 1000, loss: 0.0665, accuracy: 97.84\n",
      "[train] step: 1200, loss: 0.0664, accuracy: 97.98\n",
      "[test] step: 1200, loss: 0.0492, accuracy: 98.31\n",
      "[train] step: 1400, loss: 0.0591, accuracy: 98.17\n",
      "[test] step: 1400, loss: 0.0457, accuracy: 98.50\n",
      "[train] step: 1600, loss: 0.0510, accuracy: 98.45\n",
      "[test] step: 1600, loss: 0.0886, accuracy: 97.06\n",
      "[train] step: 1800, loss: 0.0504, accuracy: 98.47\n",
      "[test] step: 1800, loss: 0.0458, accuracy: 98.56\n",
      "[train] step: 1875, loss: 0.0577, accuracy: 98.54\n",
      "[test] step: 1875, loss: 0.0453, accuracy: 98.68\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "eval_every = 200\n",
    "train_steps = len(X_train) // batch_size + 1\n",
    "test_steps = len(X_test) // batch_size + 1\n",
    "\n",
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_accuracy\": [],\n",
    "}\n",
    "\n",
    "for step in range(train_steps):\n",
    "    sample = np.random.randint(0, len(X_train), size=batch_size)\n",
    "    images, labels = X_train[sample], Y_train[sample]\n",
    "    train_step(model, optimizer, metrics, images, labels)\n",
    "\n",
    "    if step > 0 and (step % eval_every == 0 or step == train_steps - 1):\n",
    "        for metric, value in metrics.compute().items():\n",
    "            metrics_history[f\"train_{metric}\"].append(value)\n",
    "        metrics.reset()\n",
    "\n",
    "        for test_step in range(test_steps):\n",
    "            images = X_test[batch_size*test_step:batch_size*(test_step+1)]\n",
    "            labels = Y_test[batch_size*test_step:batch_size*(test_step+1)]\n",
    "            eval_step(model, metrics, images, labels)\n",
    "\n",
    "        for metric, value in metrics.compute().items():\n",
    "            metrics_history[f\"test_{metric}\"].append(value)\n",
    "        metrics.reset()\n",
    "\n",
    "        print(\n",
    "            f\"[train] step: {step}, \"\n",
    "            f\"loss: {metrics_history['train_loss'][-1]:.4f}, \"\n",
    "            f\"accuracy: {metrics_history['train_accuracy'][-1] * 100:.2f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"[test] step: {step}, \"\n",
    "            f\"loss: {metrics_history['test_loss'][-1]:.4f}, \"\n",
    "            f\"accuracy: {metrics_history['test_accuracy'][-1] * 100:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
