{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import nnx\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rngs = nnx.Rngs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    x = x.reshape(-1, 3, 32, 32)\n",
    "    x = [[Image.fromarray(z).resize((224, 224)) for z in y] for y in x]\n",
    "    x = np.stack([np.stack([np.asarray(z) for z in y], axis=0) for y in x], axis=0)\n",
    "    x = x.reshape(-1, 224, 224, 3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cifar10\")\n",
    "\n",
    "X_train = np.array([np.array(image) for image in dataset[\"train\"][\"img\"]]) / 255.0\n",
    "Y_train = np.array(dataset[\"train\"][\"label\"], dtype=np.int32)\n",
    "\n",
    "X_test = np.array([np.array(image) for image in dataset[\"test\"][\"img\"]]) / 255.0\n",
    "Y_test = np.array(dataset[\"test\"][\"label\"], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nnx.Module):\n",
    "    def __init__(self, *, rngs):\n",
    "        self.conv1 = nnx.Conv(3, 64, kernel_size=(11, 11), strides=(4, 4), padding=(2, 2), rngs=rngs)\n",
    "        self.max_pool1 = partial(nnx.max_pool, window_shape=(3, 3), strides=(2, 2))\n",
    "        self.conv2 = nnx.Conv(64, 192, kernel_size=(5, 5), padding=(2, 2), rngs=rngs)\n",
    "        self.max_pool2 = partial(nnx.max_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "        self.conv3 = nnx.Conv(192, 384, kernel_size=(3, 3), padding=(1, 1), rngs=rngs)\n",
    "        self.conv4 = nnx.Conv(384, 256, kernel_size=(3, 3), padding=(1, 1), rngs=rngs)\n",
    "        self.conv5 = nnx.Conv(256, 256, kernel_size=(3, 3), padding=(1, 1), rngs=rngs)\n",
    "        self.max_pool3 = partial(nnx.max_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "        self.avg_pool = partial(nnx.avg_pool, window_shape=(6, 6), strides=(6, 6))\n",
    "        self.dropout1 = nnx.Dropout(0.5, rngs=rngs)\n",
    "        self.l1 = nnx.Linear(9216, 4096, rngs=rngs)\n",
    "        self.dropout2 = nnx.Dropout(0.5, rngs=rngs)\n",
    "        self.l2 = nnx.Linear(4096, 1000, rngs=rngs)\n",
    "        self.l3 = nnx.Linear(1000, 10, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.max_pool1(nnx.relu(self.conv1(x)))\n",
    "        x = self.max_pool2(nnx.relu(self.conv2(x)))\n",
    "        x = nnx.relu(self.conv3(x))\n",
    "        x = nnx.relu(self.conv4(x))\n",
    "        x = self.max_pool3(nnx.relu(self.conv5(x)))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = nnx.relu(self.l1(self.dropout1(x)))\n",
    "        x = nnx.relu(self.l2(self.dropout2(x)))\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13393363 -0.13085388 -0.01351161 -0.03580266 -0.14375003 -0.32179743\n",
      "   0.05518765  0.3839927   0.02101304 -0.00506029]]\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(rngs=rngs)\n",
    "y = model(jnp.ones((1, 224, 224, 3)))\n",
    "nnx.display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(model, optax.sgd(learning_rate, momentum))\n",
    "metrics = nnx.MultiMetric(accuracy=nnx.metrics.Accuracy(), loss=nnx.metrics.Average(\"loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=labels).mean()\n",
    "    return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, metrics, images, labels):\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(model, images, labels)\n",
    "    metrics.update(loss=loss, logits=logits, labels=labels)\n",
    "    optimizer.update(grads)\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model, metrics, images, labels):\n",
    "    loss, logits = loss_fn(model, images, labels)\n",
    "    metrics.update(loss=loss, logits=logits, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m metrics\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(test_steps):\n\u001b[0;32m---> 20\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_step\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     labels \u001b[38;5;241m=\u001b[39m Y_test[batch_size\u001b[38;5;241m*\u001b[39mtest_step:batch_size\u001b[38;5;241m*\u001b[39m(test_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     22\u001b[0m     eval_step(model, metrics, images, labels)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     x \u001b[38;5;241m=\u001b[39m [[\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m y] \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39masarray(z) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/repos/fromthetensor/env/lib/python3.12/site-packages/PIL/Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2357\u001b[0m         )\n\u001b[1;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2363\u001b[0m         )\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "eval_every = len(X_train)\n",
    "train_steps = len(X_train) // batch_size\n",
    "test_steps = len(X_test) // batch_size\n",
    "metrics_history = {\"train_loss\": [], \"train_accuracy\": [], \"test_loss\": [], \"test_accuracy\": []}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step in range(train_steps):\n",
    "        sample = np.random.randint(0, len(X_train), size=batch_size)\n",
    "        images, labels = transform(X_train[sample]), Y_train[sample]\n",
    "        train_step(model, optimizer, metrics, images, labels)\n",
    "\n",
    "        if step > 0 and (step % eval_every == 0 or step == train_steps - 1):\n",
    "            for metric, value in metrics.compute().items():\n",
    "                metrics_history[f\"train_{metric}\"].append(value)\n",
    "            metrics.reset()\n",
    "\n",
    "            for test_step in range(test_steps):\n",
    "                images = transform(X_test[batch_size*test_step:batch_size*(test_step+1)])\n",
    "                labels = Y_test[batch_size*test_step:batch_size*(test_step+1)]\n",
    "                eval_step(model, metrics, images, labels)\n",
    "\n",
    "            for metric, value in metrics.compute().items():\n",
    "                metrics_history[f\"test_{metric}\"].append(value)\n",
    "            metrics.reset()\n",
    "\n",
    "            print(\n",
    "                f\"[train] epoch: {epoch}, step: {step}, \"\n",
    "                f\"loss: {metrics_history['train_loss'][-1]:.4f}, \"\n",
    "                f\"accuracy: {metrics_history['train_accuracy'][-1] * 100:.2f}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"[test] epoch: {epoch}, step: {step}, \"\n",
    "                f\"loss: {metrics_history['test_loss'][-1]:.4f}, \"\n",
    "                f\"accuracy: {metrics_history['test_accuracy'][-1] * 100:.2f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
